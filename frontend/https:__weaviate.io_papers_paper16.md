# https:\_\_weaviate.io_papers_paper16

A breakdown of the Long Context Retrieval Embedding Models from Stanford. They release 3 long context(2k/8k/32k) BERT-like encoder embedding models on HuggingFace. The models are only 80M params and outperform larger models (4-85x larger)
