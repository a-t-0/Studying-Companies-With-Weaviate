# https:\_\_weaviate.io_papers_paper-4

Synthetic data is quite promising, but to see how far we can push the limit with it, this paper investigates what happens when text produced by a version of GPT forms most of the training dataset. What happens to GPT versions GPT-{n} as generation n increases? In short, it was found that "model-collapse" occurs.
