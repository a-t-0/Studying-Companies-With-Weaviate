# https:\_\_weaviate.io_papers_page_3

A new way to chunk your data using LLM's. Compares finetuning vs RAG for improvement on a specific domain. Getting an LLM to check its own responses for hallucination. Getting LLMs to forget by finetuned. Using prompt engineering to solve the 'lost in the middle' problem.
