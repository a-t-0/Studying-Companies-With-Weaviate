# https:\_\_weaviate.io_papers_paper11

Researchers from Microsoft asked if unsupervised next token prediction finetuning is better than RAG to improve LLM perf. on both seen and unseen QnA tasks. RAG is a better way to inject knowledge into LLMs than unsuper supervised fine-tuning(USFT)
