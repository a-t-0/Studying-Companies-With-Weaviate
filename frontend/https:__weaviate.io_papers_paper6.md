# https:\_\_weaviate.io_papers_paper6

Multimodal RAG allows you to pack retrieved context into a prompt so that a language model can read relevant information before generating a response. This function is critical and allows us to integrate knowledge in a more scalable and modular way into LLMs. Vector databases provide an ideal store from which multimedia knowledge can be retrieved and can capture the meaning of all of these modalities.
